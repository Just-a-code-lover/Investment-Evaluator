{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPFP8ClmMe70QRKklDgfsw+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Just-a-code-lover/Investment-Evaluator/blob/main/Invest_Advisor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import PegasusTokenizer, PegasusForConditionalGeneration\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize\n",
        "import re\n",
        "import time\n",
        "from typing import List, Dict, Any\n",
        "import PyPDF2\n",
        "import requests\n",
        "from google.colab import files\n",
        "import json\n",
        "\n",
        "class DialogueSummarizer:\n",
        "    def __init__(self, chunk_size: int = 3000):\n",
        "        \"\"\"\n",
        "        Initialize the dialogue summarizer with Pegasus model and configurations.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            nltk.data.find('tokenizers/punkt')\n",
        "        except LookupError:\n",
        "            nltk.download('punkt')\n",
        "\n",
        "        self.chunk_size = chunk_size\n",
        "\n",
        "        print(\"Loading Pegasus model...\")\n",
        "        self.model_name = \"human-centered-summarization/financial-summarization-pegasus\"\n",
        "        self.tokenizer = PegasusTokenizer.from_pretrained(self.model_name)\n",
        "        self.model = PegasusForConditionalGeneration.from_pretrained(self.model_name)\n",
        "\n",
        "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        self.model = self.model.to(self.device)\n",
        "        print(f\"Model loaded. Using device: {self.device}\")\n",
        "\n",
        "    def extract_text_from_pdf(self, pdf_path: str) -> str:\n",
        "        \"\"\"\n",
        "        Extract text from PDF while preserving speaker attributions.\n",
        "        \"\"\"\n",
        "        with open(pdf_path, 'rb') as file:\n",
        "            pdf_reader = PyPDF2.PdfReader(file)\n",
        "            text = \"\"\n",
        "            for page in pdf_reader.pages:\n",
        "                text += page.extract_text() + \"\\n\"\n",
        "        return text\n",
        "\n",
        "    def parse_dialogue(self, text: str) -> List[Dict]:\n",
        "        \"\"\"\n",
        "        Parse text into structured dialogue format.\n",
        "        \"\"\"\n",
        "        dialogue_segments = []\n",
        "        lines = text.split('\\n')\n",
        "        current_speaker = None\n",
        "        current_content = []\n",
        "\n",
        "        for line in lines:\n",
        "            line = line.strip()\n",
        "            if not line:\n",
        "                continue\n",
        "\n",
        "            speaker_match = re.match(r'^([^:]+):\\s*(.*)$', line)\n",
        "\n",
        "            if speaker_match:\n",
        "                if current_speaker and current_content:\n",
        "                    dialogue_segments.append({\n",
        "                        'speaker': current_speaker,\n",
        "                        'content': ' '.join(current_content)\n",
        "                    })\n",
        "                    current_content = []\n",
        "\n",
        "                current_speaker = speaker_match.group(1).strip()\n",
        "                content = speaker_match.group(2).strip()\n",
        "                if content:\n",
        "                    current_content.append(content)\n",
        "            else:\n",
        "                if current_speaker:\n",
        "                    current_content.append(line)\n",
        "\n",
        "        if current_speaker and current_content:\n",
        "            dialogue_segments.append({\n",
        "                'speaker': current_speaker,\n",
        "                'content': ' '.join(current_content)\n",
        "            })\n",
        "\n",
        "        return dialogue_segments\n",
        "\n",
        "    def clean_text(self, text: str) -> str:\n",
        "        \"\"\"\n",
        "        Clean and preprocess the input text while preserving speaker attributions.\n",
        "        \"\"\"\n",
        "        text = re.sub(r'\\s+', ' ', text)\n",
        "        text = re.sub(r'\\[.*?\\]', '', text)\n",
        "        text = ' '.join(text.split())\n",
        "        return text.strip()\n",
        "\n",
        "    def split_into_chunks(self, dialogue_segments: List[Dict]) -> List[List[Dict]]:\n",
        "        \"\"\"\n",
        "        Split dialogue segments into chunks while preserving speaker context.\n",
        "        \"\"\"\n",
        "        chunks = []\n",
        "        current_chunk = []\n",
        "        current_length = 0\n",
        "\n",
        "        for segment in dialogue_segments:\n",
        "            segment_length = len(segment['content'])\n",
        "\n",
        "            if current_length + segment_length > self.chunk_size:\n",
        "                if current_chunk:\n",
        "                    chunks.append(current_chunk)\n",
        "                current_chunk = [segment]\n",
        "                current_length = segment_length\n",
        "            else:\n",
        "                current_chunk.append(segment)\n",
        "                current_length += segment_length\n",
        "\n",
        "        if current_chunk:\n",
        "            chunks.append(current_chunk)\n",
        "\n",
        "        return chunks\n",
        "\n",
        "    def format_chunk_for_summarization(self, chunk: List[Dict]) -> str:\n",
        "        \"\"\"\n",
        "        Format a chunk of dialogue segments for summarization.\n",
        "        \"\"\"\n",
        "        formatted_text = \"\"\n",
        "        for segment in chunk:\n",
        "            formatted_text += f\"{segment['speaker']}: {segment['content']}\\n\"\n",
        "        return formatted_text\n",
        "\n",
        "    def summarize_chunk(self, chunk: List[Dict], max_length: int = 150) -> str:\n",
        "        \"\"\"\n",
        "        Summarize a chunk of dialogue while preserving speaker context.\n",
        "        \"\"\"\n",
        "        formatted_text = self.format_chunk_for_summarization(chunk)\n",
        "\n",
        "        inputs = self.tokenizer(formatted_text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
        "        inputs = inputs.to(self.device)\n",
        "\n",
        "        summary_ids = self.model.generate(\n",
        "            inputs.input_ids,\n",
        "            max_length=max_length,\n",
        "            num_beams=4,\n",
        "            length_penalty=2.0,\n",
        "            early_stopping=True,\n",
        "            no_repeat_ngram_size=3\n",
        "        )\n",
        "\n",
        "        summary = self.tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "        return summary\n",
        "\n",
        "    def process_document(self, pdf_path: str, verbose: bool = True) -> Dict:\n",
        "        \"\"\"\n",
        "        Process the entire PDF document: extract text, parse dialogue, chunk, and summarize.\n",
        "        \"\"\"\n",
        "        if verbose:\n",
        "            print(\"Extracting text from PDF...\")\n",
        "        text = self.extract_text_from_pdf(pdf_path)\n",
        "\n",
        "        if verbose:\n",
        "            print(\"Parsing dialogue...\")\n",
        "        dialogue_segments = self.parse_dialogue(text)\n",
        "\n",
        "        if verbose:\n",
        "            print(\"Splitting into chunks...\")\n",
        "        chunks = self.split_into_chunks(dialogue_segments)\n",
        "\n",
        "        if verbose:\n",
        "            print(f\"Generated {len(chunks)} chunks. Summarizing each chunk...\")\n",
        "\n",
        "        chunk_summaries = []\n",
        "        formatted_chunks = []\n",
        "\n",
        "        for i, chunk in enumerate(chunks, 1):\n",
        "            if verbose:\n",
        "                print(f\"Processing chunk {i}/{len(chunks)}...\")\n",
        "\n",
        "            formatted_chunk = self.format_chunk_for_summarization(chunk)\n",
        "            formatted_chunks.append(formatted_chunk)\n",
        "\n",
        "            summary = self.summarize_chunk(chunk)\n",
        "            chunk_summaries.append(summary)\n",
        "\n",
        "            if verbose:\n",
        "                print(f\"Generated summary length: {len(summary)} characters\")\n",
        "                print(\"---\")\n",
        "\n",
        "            time.sleep(1)\n",
        "\n",
        "        combined_summary = \" \".join(chunk_summaries)\n",
        "\n",
        "        return {\n",
        "            'dialogue_segments': dialogue_segments,\n",
        "            'formatted_chunks': formatted_chunks,\n",
        "            'chunk_summaries': chunk_summaries,\n",
        "            'combined_summary': combined_summary\n",
        "        }\n",
        "\n",
        "class GPTAnalyzer:\n",
        "    def __init__(self, api_key: str):\n",
        "        \"\"\"\n",
        "        Initialize the GPT Analyzer with RapidAPI configuration.\n",
        "        \"\"\"\n",
        "        self.url = \"https://chatgpt-42.p.rapidapi.com/conversationgpt4-2\"\n",
        "        self.headers = {\n",
        "            \"x-rapidapi-key\": api_key,\n",
        "            \"x-rapidapi-host\": \"chatgpt-42.p.rapidapi.com\",\n",
        "            \"Content-Type\": \"application/json\"\n",
        "        }\n",
        "\n",
        "    def create_analysis_prompt(self, text: str) -> str:\n",
        "        \"\"\"\n",
        "        Create a detailed prompt for financial analysis.\n",
        "        \"\"\"\n",
        "        return f\"\"\"As an investment advisor, analyze the following earnings call transcript\n",
        "        and provide specific actionable insights for investors. Focus on:\n",
        "\n",
        "        1. Future Growth Prospects:\n",
        "        - Identify specific growth initiatives\n",
        "        - Evaluate market expansion plans\n",
        "        - Assess new product/service developments\n",
        "\n",
        "        2. Key Business Changes:\n",
        "        - Recent strategic shifts\n",
        "        - Management changes\n",
        "        - Operational modifications\n",
        "\n",
        "        3. Key Triggers & Catalysts:\n",
        "        - Upcoming milestones\n",
        "        - Potential market opportunities\n",
        "        - Strategic partnerships or acquisitions\n",
        "\n",
        "        4. Material Information for Future Earnings:\n",
        "        - Revenue drivers\n",
        "        - Margin trends\n",
        "        - Cost management initiatives\n",
        "        - Market conditions impact\n",
        "\n",
        "        5. Investment Advice:\n",
        "        - Key risks and mitigation strategies\n",
        "        - Competitive advantages\n",
        "        - Recommended investor action points\n",
        "\n",
        "        Transcript:\n",
        "        {text}\n",
        "\n",
        "        Provide a structured analysis with specific numbers and timelines where mentioned.\n",
        "        Include actionable recommendations for investors.\"\"\"\n",
        "\n",
        "    def get_gpt_analysis(self, text: str, max_retries: int = 3) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Get GPT analysis with retry mechanism.\n",
        "        \"\"\"\n",
        "        prompt = self.create_analysis_prompt(text)\n",
        "        payload = {\n",
        "            \"messages\": [\n",
        "                {\n",
        "                    \"role\": \"user\",\n",
        "                    \"content\": prompt\n",
        "                }\n",
        "            ],\n",
        "            \"system_prompt\": \"You are an experienced financial analyst providing detailed insights for investors.\",\n",
        "            \"temperature\": 0.7,\n",
        "            \"top_k\": 5,\n",
        "            \"top_p\": 0.9,\n",
        "            \"max_tokens\": 1000,\n",
        "            \"web_access\": False\n",
        "        }\n",
        "\n",
        "        for attempt in range(max_retries):\n",
        "            try:\n",
        "                response = requests.post(self.url, json=payload, headers=self.headers)\n",
        "                response.raise_for_status()\n",
        "                return response.json()\n",
        "            except requests.exceptions.RequestException as e:\n",
        "                if attempt == max_retries - 1:\n",
        "                    raise Exception(f\"Failed to get GPT analysis after {max_retries} attempts: {str(e)}\")\n",
        "                time.sleep(2 ** attempt)  # Exponential backoff\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Main function to run the complete analysis pipeline.\n",
        "    \"\"\"\n",
        "    # Your RapidAPI key\n",
        "    api_key = \"Refer to the email send to you\"\n",
        "\n",
        "    # Initialize both summarizer and analyzer\n",
        "    summarizer = DialogueSummarizer(chunk_size=1000)\n",
        "    analyzer = GPTAnalyzer(api_key)\n",
        "\n",
        "    print(\"Please upload your PDF file...\")\n",
        "    uploaded = files.upload()\n",
        "    pdf_filename = list(uploaded.keys())[0]\n",
        "\n",
        "    try:\n",
        "        # Get document summary\n",
        "        print(\"\\nProcessing document...\")\n",
        "        doc_results = summarizer.process_document(pdf_filename)\n",
        "        combined_summary = doc_results['combined_summary']\n",
        "\n",
        "        print(\"\\nDocument Processing Results:\")\n",
        "        print(\"=\" * 50)\n",
        "        print(\"\\nDialogue Segments:\")\n",
        "        for segment in doc_results['dialogue_segments']:\n",
        "            print(f\"\\n{segment['speaker']}:\")\n",
        "            print(segment['content'][:100] + \"...\" if len(segment['content']) > 100 else segment['content'])\n",
        "\n",
        "        print(\"\\nChunk Summaries:\")\n",
        "        for i, summary in enumerate(doc_results['chunk_summaries'], 1):\n",
        "            print(f\"\\nSummary {i}:\")\n",
        "            print(summary)\n",
        "\n",
        "        # Get GPT analysis\n",
        "        print(\"\\nAnalyzing with GPT...\")\n",
        "        analysis_results = analyzer.get_gpt_analysis(combined_summary)\n",
        "\n",
        "        print(\"\\nInvestment Analysis Results:\")\n",
        "        print(\"=\" * 50)\n",
        "\n",
        "        if isinstance(analysis_results, dict) and 'choices' in analysis_results:\n",
        "            # Extract the analysis text\n",
        "            analysis_text = analysis_results['choices'][0]['message']['content']\n",
        "\n",
        "            # Print analysis with proper formatting, replacing \"\\n\" with actual newlines\n",
        "            print(analysis_text.replace(\"\\\\n\", \"\\n\"))\n",
        "        else:\n",
        "            print(\"My Advice:\", analysis_results)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error during document processing: {str(e)}\")\n",
        "        raise\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Install required packages\n",
        "    !pip install transformers nltk torch PyPDF2\n",
        "\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "uFN9KQWjIZIu",
        "outputId": "4066249b-55a6-40c5-bf52-5850c8ab3062"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.0+cu121)\n",
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.10/dist-packages (3.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Loading Pegasus model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at human-centered-summarization/financial-summarization-pegasus and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded. Using device: cpu\n",
            "Please upload your PDF file...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-43e91b09-7e79-4bad-acc4-5d53d4660b76\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-43e91b09-7e79-4bad-acc4-5d53d4660b76\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving SJS Transcript Call.pdf to SJS Transcript Call (6).pdf\n",
            "\n",
            "Processing document...\n",
            "Extracting text from PDF...\n",
            "Parsing dialogue...\n",
            "Splitting into chunks...\n",
            "Generated 45 chunks. Summarizing each chunk...\n",
            "Processing chunk 1/45...\n",
            "Generated summary length: 81 characters\n",
            "---\n",
            "Processing chunk 2/45...\n",
            "Generated summary length: 89 characters\n",
            "---\n",
            "Processing chunk 3/45...\n",
            "Generated summary length: 70 characters\n",
            "---\n",
            "Processing chunk 4/45...\n",
            "Generated summary length: 73 characters\n",
            "---\n",
            "Processing chunk 5/45...\n",
            "Generated summary length: 86 characters\n",
            "---\n",
            "Processing chunk 6/45...\n",
            "Generated summary length: 53 characters\n",
            "---\n",
            "Processing chunk 7/45...\n",
            "Generated summary length: 68 characters\n",
            "---\n",
            "Processing chunk 8/45...\n",
            "Generated summary length: 76 characters\n",
            "---\n",
            "Processing chunk 9/45...\n",
            "Generated summary length: 79 characters\n",
            "---\n",
            "Processing chunk 10/45...\n",
            "Generated summary length: 74 characters\n",
            "---\n",
            "Processing chunk 11/45...\n",
            "Generated summary length: 67 characters\n",
            "---\n",
            "Processing chunk 12/45...\n",
            "Generated summary length: 87 characters\n",
            "---\n",
            "Processing chunk 13/45...\n",
            "Generated summary length: 71 characters\n",
            "---\n",
            "Processing chunk 14/45...\n",
            "Generated summary length: 149 characters\n",
            "---\n",
            "Processing chunk 15/45...\n",
            "Generated summary length: 113 characters\n",
            "---\n",
            "Processing chunk 16/45...\n",
            "Generated summary length: 116 characters\n",
            "---\n",
            "Processing chunk 17/45...\n",
            "Generated summary length: 61 characters\n",
            "---\n",
            "Processing chunk 18/45...\n",
            "Generated summary length: 83 characters\n",
            "---\n",
            "Processing chunk 19/45...\n",
            "Generated summary length: 86 characters\n",
            "---\n",
            "Processing chunk 20/45...\n",
            "Generated summary length: 56 characters\n",
            "---\n",
            "Processing chunk 21/45...\n",
            "Generated summary length: 62 characters\n",
            "---\n",
            "Processing chunk 22/45...\n",
            "Generated summary length: 67 characters\n",
            "---\n",
            "Processing chunk 23/45...\n",
            "Generated summary length: 121 characters\n",
            "---\n",
            "Processing chunk 24/45...\n",
            "Generated summary length: 111 characters\n",
            "---\n",
            "Processing chunk 25/45...\n",
            "Generated summary length: 73 characters\n",
            "---\n",
            "Processing chunk 26/45...\n",
            "Generated summary length: 77 characters\n",
            "---\n",
            "Processing chunk 27/45...\n",
            "Generated summary length: 94 characters\n",
            "---\n",
            "Processing chunk 28/45...\n",
            "Generated summary length: 65 characters\n",
            "---\n",
            "Processing chunk 29/45...\n",
            "Generated summary length: 66 characters\n",
            "---\n",
            "Processing chunk 30/45...\n",
            "Generated summary length: 101 characters\n",
            "---\n",
            "Processing chunk 31/45...\n",
            "Generated summary length: 55 characters\n",
            "---\n",
            "Processing chunk 32/45...\n",
            "Generated summary length: 87 characters\n",
            "---\n",
            "Processing chunk 34/45...\n",
            "Generated summary length: 100 characters\n",
            "---\n",
            "Processing chunk 35/45...\n",
            "Generated summary length: 87 characters\n",
            "---\n",
            "Processing chunk 36/45...\n",
            "Generated summary length: 104 characters\n",
            "---\n",
            "Processing chunk 37/45...\n",
            "Generated summary length: 77 characters\n",
            "---\n",
            "Processing chunk 38/45...\n",
            "Generated summary length: 69 characters\n",
            "---\n",
            "Processing chunk 39/45...\n",
            "Generated summary length: 74 characters\n",
            "---\n",
            "Processing chunk 40/45...\n",
            "Generated summary length: 101 characters\n",
            "---\n",
            "Processing chunk 41/45...\n",
            "Generated summary length: 50 characters\n",
            "---\n",
            "Processing chunk 42/45...\n",
            "Generated summary length: 99 characters\n",
            "---\n",
            "Processing chunk 43/45...\n",
            "Generated summary length: 80 characters\n",
            "---\n",
            "Processing chunk 44/45...\n",
            "Generated summary length: 96 characters\n",
            "---\n",
            "Processing chunk 45/45...\n",
            "Generated summary length: 100 characters\n",
            "---\n",
            "\n",
            "Document Processing Results:\n",
            "==================================================\n",
            "\n",
            "Dialogue Segments:\n",
            "\n",
            "Symbol:\n",
            "SJS  BSE Limited Corporate Relationship Department, 2nd Floor, New Trading Wing, Rotunda Building, P...\n",
            "\n",
            "Scrip Code:\n",
            "543387\n",
            "\n",
            "ISIN:\n",
            "INE284S01014 Dear Sir/Madam,\n",
            "\n",
            "Subject:\n",
            "Transcripts of Analysts/Investor Meet/ Earnings Call of the Company pertaining to Q1 of FY 2023-24 P...\n",
            "\n",
            "Membership No.:\n",
            "A51119\n",
            "\n",
            "Encl:\n",
            "As above SJS Enterprises Limited Q1 FY202 4 Earnings Conference Call July 27, 202 3\n",
            "\n",
            "ANALYST:\n",
            "MR. RONAK MEHTA  – JM FINANCIAL\n",
            "\n",
            "MANAGEMENT:\n",
            "MR. K.A.  JOSEPH – MANAGING DIRECTOR  & CO-FOUNDER MR. SANJAY THAPAR – CEO  & EXECUTIVE DIRECTOR MR....\n",
            "\n",
            "Moderator:\n",
            "Ladies and gentlemen, good day and welcome to the SJS Enterprises 1Q FY24 Earnings Conference Call h...\n",
            "\n",
            "Ronak Mehta:\n",
            "From JM  Financial Institutional Securities , I welcome you all to 1Q FY2 4 Earnings Call of SJS Ent...\n",
            "\n",
            "Devanshi Dhruva:\n",
            "Thank you, Ronak . Good morning, ladies and gentlemen, and thank you for being with us over the call...\n",
            "\n",
            "K.A. Joseph:\n",
            "Thank you , Devanshi for the introduction. Hello and good morning , everyone. I trust you had a chan...\n",
            "\n",
            "Sanjay  Thapar:\n",
            "Yes. Thank you, Joe, for updating our investors and analysts on W alter P ack. Very  good morning ev...\n",
            "\n",
            "Starting with our Q1 highlights:\n",
            "SJS Enterprises July 27, 2023 We have seen a robust start to FY 24 financial year as we yet again ou...\n",
            "\n",
            "Mahendr a Naredi:\n",
            "Thank you, Mr. Thapar. Good morning, everyone. Moving to slide 12, which talks about our financial p...\n",
            "\n",
            "Sanjay Thapar:\n",
            "Thank you, Mahendra. Moving ahead, we are absolutely on track in executing our orga nic growth strat...\n",
            "\n",
            "Moderator:\n",
            "Thank you very much. We will now begin the question -and-answer session. Our first question is from ...\n",
            "\n",
            "Amit Hiranandani:\n",
            "My first question is basically what was the contribution from new products in the consolidated reven...\n",
            "\n",
            "Mahendra Naredi:\n",
            "So Amit, a good question and our contribution for this quarter was around 10% and it was around the ...\n",
            "\n",
            "Amit Hiranandani:\n",
            "And sir, we understand that Exotech margins on Q oQ has slightly dropped , possibly we understand th...\n",
            "\n",
            "Mahendra Naredi:\n",
            "So Amit, as we already guided in the past, there was a small blip in this quarter, but , however Exo...\n",
            "\n",
            "Amit Hiranandani:\n",
            "And sir, where do you see it in the next three years … any chance to improve it further?\n",
            "\n",
            "Sanj ay Thapar:\n",
            "So as I have said earlier in our previous  calls, we had inherited a legacy of existing customers. S...\n",
            "\n",
            "Devanshi Dhruva:\n",
            "So see , definitely in the last two years as you know once we've acquired it, this business was actu...\n",
            "\n",
            "Amit Hiranandani:\n",
            "Next on the Exotech's  new plant capacity expansion, I just missed the initial comment. Can you plea...\n",
            "\n",
            "Sanjay Thapar:\n",
            "No, it's not delayed , it's a conscious decision on our  part, because when we guided you on expansi...\n",
            "\n",
            "Devanshi Dhruva:\n",
            "Basically , we would just want to be more effective and be very frugal with our investment . If this...\n",
            "\n",
            "Amit Hiranandani:\n",
            "Then, sir, you must be having some revised CAPEX guidance, right for Exotech and standalone separa t...\n",
            "\n",
            "Devanshi Dhruva:\n",
            "Yes. So for this year FY24, SJS would be somewhere around 1 0-12 crores and Exotech would be another...\n",
            "\n",
            "Moderator:\n",
            "Our next question is from the line of Joseph George from I IFL. Please go ahead.\n",
            "\n",
            "Joseph Geor ge:\n",
            "Just one question on the postponement of the Exotech capacity. You mentioned that in the interim you...\n",
            "\n",
            "Mahendra Naredi:\n",
            "Yes, Mr. Joseph, we believe that it will not impact our margins. Yes, in an outsourcing model, the r...\n",
            "\n",
            "Sanjay Thapar:\n",
            "And just to add to this, so it is not that we are postponing the CAPEX , we are only doing it more i...\n",
            "\n",
            "Devanshi Dhruva:\n",
            "Moreover, if you will look at a consolidated basis, we will try and maintain our 25% to 27% margins ...\n",
            "\n",
            "Amit Hiranandani:\n",
            "And the second question was when you say that the CAPEX has been postponed, our  old understanding w...\n",
            "\n",
            "Sanjay Thapar:\n",
            "No, nothing . Absolutely , we are on track. We are still holding those  numbers. It's only a smarter...\n",
            "\n",
            "Moderator:\n",
            "Our next question is from th e line of Piyush Parag from Nuvama Wealth. Please go ahead.\n",
            "\n",
            "Piyush Parag:\n",
            "So my questions would be more on the WPI label . If you can just throw some light in terms of the ac...\n",
            "\n",
            "Devanshi Dhruva:\n",
            "Could you just be a little louder ?\n",
            "\n",
            "Piyush Parag:\n",
            "My question was more on the WPI performance. How has  it been  during the quarter and how do we see ...\n",
            "\n",
            "Mahendra Naredi:\n",
            "So Walter Pack  India has done  this quarter 356 million  sales turnover with an EBITDA  of 31.5% . ...\n",
            "\n",
            "Sanjay Thapar:\n",
            "So let me supplement that by giving you an outlook on Walter Pack . It just puts SJS into another tr...\n",
            "\n",
            "Devanshi Dhruva:\n",
            "So for F Y24, as we have guided last time also , overall consol growth including WP I will be 50%. S...\n",
            "\n",
            "Moderator:\n",
            "Our next question is from the line of Mr. Ronak Mehta from JM Financial. Please go ahead with your q...\n",
            "\n",
            "Ronak Mehta:\n",
            "So continuing on WPI, wanted to check so what are the opportunity areas for cross selling from the e...\n",
            "\n",
            "K.A. Joseph:\n",
            "One is we have a cross selling opportuni ty between two companies. They also make some dial , overla...\n",
            "\n",
            "Sanjay Thapar:\n",
            "Just to supplement what Joe just said. So as I said, large in -mold forming parts are the forte of W...\n",
            "\n",
            "Devanshi Dhruva:\n",
            "Especially, on the Exotech and on the Walter Pack side, both the places we have added new passenger ...\n",
            "\n",
            "Ronak Mehta:\n",
            "On the recent addition of the new clients, Autoliv and Toyota  Tsusho, so just wanted to clarify , w...\n",
            "\n",
            "Sanjay Thapar:\n",
            "Our strategy always has been that we take customers and we grow them into mega  counts . So our focu...\n",
            "\n",
            "Ronak Mehta:\n",
            "One more housekeeping question to Mah endra. So Mah endra on the consol financials, other expenses h...\n",
            "\n",
            "Devanshi Dhruva:\n",
            "So other expenses have increased on account of two reasons. One is that there has been a n increase ...\n",
            "\n",
            "Moderator:\n",
            "Our next question is from the line of Karn Bhargava from We althB ridge Capital Advisors. Please go ...\n",
            "\n",
            "Karn Bhargava:\n",
            "I have two questions . I think I misheard the number for the WPI revenue. If you could just clarify ...\n",
            "\n",
            "Devanshi Dhruva:\n",
            "WPI revenue for this quarter grew 21% YoY to Rs 356 million.\n",
            "\n",
            "Karn Bhargava:\n",
            "There's been a lot of talk on the IME side , that's the In-Mold Electronics . And I think last we sp...\n",
            "\n",
            "Sanjay Thapar:\n",
            "So the applications are quite diverse, so we are looking at the two wheelers , we're looking at four...\n",
            "\n",
            "Karn Bhargava:\n",
            "Walter Pack , Spain  will be helping you out with the development of the  product as well ?\n",
            "\n",
            "K.A. Joseph:\n",
            "Absolutely.\n",
            "\n",
            "Moderator:\n",
            "Our next question is from the line of Sh rinjan a Mitta l from Ratn aTraya Capital. Please go ahead.\n",
            "\n",
            "Shrinjana Mittal:\n",
            "Sir, two questions from my side. One is on Exotech  sales quarter -on-quarter was also slightly done...\n",
            "\n",
            "Devanshi Dhruva:\n",
            "So generally also if you will see Q2 and Q4 are usually stronger quarters for us due to festive seas...\n",
            "\n",
            "Sanjay Thapar:\n",
            "Exotech this year grew a little  lower  because the farm equipment demand was soft . So John Deere i...\n",
            "\n",
            "Shrinjana Mittal:\n",
            "Second question is on exports . Like you mentioned, I think around 11 % is the co ntribution. Just w...\n",
            "\n",
            "Mahendra Naredi:\n",
            "Last quarter our export was 7.9 % which has now gone up to  11%.\n",
            "\n",
            "Devanshi Dhruva:\n",
            "In fact the entire last year, if you will see because of the geopolitical issues in Europe as well a...\n",
            "\n",
            "Shrinja na Mittal:\n",
            "So like going forward like for the year organically we are guiding for around 20 %, 25% only for exp...\n",
            "\n",
            "Sanjay Thapar:\n",
            "We don't provide guidance specifically, but as I said earlier in my co mmentary , on QoQ basis, expo...\n",
            "\n",
            "Moderator:\n",
            "Our next question is from the line of Ridhima Goyal from Acquaintbee  Ventures. Please go ahead.\n",
            "\n",
            "Ridhima Goyal:\n",
            "Hi, Sanjay and hi Devanshi. Just one question from my end is what is the consumer durable on the ove...\n",
            "\n",
            "Devanshi Dhruva:\n",
            "Sorry, can you repeat the second part of  your question ?\n",
            "\n",
            "Ridhima Goyal:\n",
            "What was the growth for this quarter in the consume r durables part? SJS Enterprises July 27, 2023\n",
            "\n",
            "Devanshi Dhruva:\n",
            "So consumer durables was a little muted growth ; I would say almost about 2% - 3% and overall as a p...\n",
            "\n",
            "Ridhima Goyal:\n",
            "I know that you guys don't disclose your order book as such.\n",
            "\n",
            "Devanshi Dhruva:\n",
            "Can you be a little louder ?\n",
            "\n",
            "Ridhima Goyal:\n",
            "I know that you guys don't disclose your order book as such, but it would be great if you can give s...\n",
            "\n",
            "Sanjay Thapar:\n",
            "So consumer durables is a very important segment for us and we have made further inroads  by this Wa...\n",
            "\n",
            "Devanshi Dhruva:\n",
            "Also, if you'll notice, last year we added Mabe group and even I FB on our consumer appliances front...\n",
            "\n",
            "Ridhima Goyal:\n",
            "I understand your point, but my question was related to the order book. It would be great if you can...\n",
            "\n",
            "Devanshi Dhruva:\n",
            "We do not give order book segment wise or anything. Overall , what we have guided for is 20 % to 25%...\n",
            "\n",
            "Ridhima Goyal:\n",
            "Including WPI?\n",
            "\n",
            "Devanshi Dhruva:\n",
            "No, not including WP I, but on th e WP I front also , almost around 90% of the order book is confirm...\n",
            "\n",
            "Ridhima Goyal:\n",
            "I need to understand was, do we have some common customers between WPI and SJS as a whole ?\n",
            "\n",
            "Sanjay Thapar:\n",
            "Yes, we do.  But a very small overlap. So WPI supplies to Tata Motors  and we supply to Tata Motors ...\n",
            "\n",
            "Moderator:\n",
            "Our next question is from the line of Rohan Ad vant from Multi Act. Please go ahead.\n",
            "\n",
            "Rohan Advant:\n",
            "My first question was on the technical support fees that Walter Pack pays to its parents. What was i...\n",
            "\n",
            "Mahendra Naredi:\n",
            "Earlier the technical fees paid by Walter Pack  was in the range of 3 .5% of the sales value. We hav...\n",
            "\n",
            "Rohan Advant:\n",
            "When you've done the pro forma calculation, you've considered 1% because that is what  has to be pai...\n",
            "\n",
            "Mahendra Naredi:\n",
            "That has been considered, yes.\n",
            "\n",
            "Roha n Advant:\n",
            "Secondly, our guidance of 50% revenue growth and 40% profit growth, but Walter Pack is a higher marg...\n",
            "\n",
            "Sanjay Thapar:\n",
            "As I mentioned earlier, so we are in a transformation stage. Think of it as the whole entity. So thi...\n",
            "\n",
            "Mahendra Naredi:\n",
            "And just to supplement here, one is the business side. Anot her is when we made the acquisition of W...\n",
            "\n",
            "Moderator:\n",
            "Our next question is from the line of Amit Hiranandani from SMIFS Limited. Please go ahead.\n",
            "\n",
            "Amit Hiranandani:\n",
            "Just continuing with the WP I side, if you sir can  tell us more about going forward strategy in dom...\n",
            "\n",
            "Sanjay Thapar:\n",
            "So as I said, the WPI is a great acquisition for us. There is a technology support agreement that is...\n",
            "\n",
            "Devanshi Dhruva:\n",
            "Overall, as a company for S JS and Exotech put together organic ally, we have mentioned that it will...\n",
            "\n",
            "Amit Hiranandani:\n",
            "I'll just rephrase it. So at the optimum utilization capacity of WPI, how much revenue we can genera...\n",
            "\n",
            "Devanshi Dhruva:\n",
            "Currently , we are at a capacity utilization of 60 % to 70% and we can generate revenue close to Rs....\n",
            "\n",
            "Amit Hiranandani:\n",
            "Rs.200 crores you are saying at full utilization?\n",
            "\n",
            "Devanshi Dhruva:\n",
            "Yes.\n",
            "\n",
            "Amit Hiranandani:\n",
            "One last qu estion from my side on the standalone side , so SJS I understand is trying to acquire so...\n",
            "\n",
            "Sanjay Thapar:\n",
            "So these customers are both domestic and export customers and it is for the existing customers it is...\n",
            "\n",
            "Amit Hiranandani:\n",
            "Just one request , from Q2 FY24, we are going to incorporate WPI in the consolidated numbers. So it'...\n",
            "\n",
            "Moderator:\n",
            "Our next question is from the line of Vishal Khurana, who's an investor. Please go ahead.\n",
            "\n",
            "Vishal Khurana:\n",
            "My first question is, so we are almost  providing the aesthetics to almost every two wheeler OEM, ex...\n",
            "\n",
            "Sanjay Thapar:\n",
            "So Hero is a company that we've been pursuing. They li ke us, they visited and audited us . The ball...\n",
            "\n",
            "Devanshi Dhruva:\n",
            "Their current supplier is Classic Stripes . SJS Enterprises July 27, 2023\n",
            "\n",
            "Vishal Khurana:\n",
            "Second question is in the previous quarter investor presentation, we had mentioned that we had onboa...\n",
            "\n",
            "Sanjay Thapar:\n",
            "No, no, Foxconn  is not going to make EV , Foxconn  is going to supply parts to EV. And we announced...\n",
            "\n",
            "Vishal Khurana:\n",
            "We also discussed about that we'll be entering into television and medical dev ices aesthetic segmen...\n",
            "\n",
            "Sanjay Thapar:\n",
            "We w on a business for some decorative deca ls for the television industry , so that we've done . Me...\n",
            "\n",
            "Vishal Khurana:\n",
            "How big can this TV opportunity be since we are manu facturing a lot of television and other electro...\n",
            "\n",
            "Sanjay Thapar:\n",
            "It is wait-and-watch . Our specialty is make long lasting durable aesthetic parts. So the opportunit...\n",
            "\n",
            "Moderator:\n",
            "Ladies and gentlemen, that was t he last question of our question -and-answer session. I would now l...\n",
            "\n",
            "Devanshi Dhruva:\n",
            "Thank you everyone for joining us on this call. If any of the questions were left unanswered, please...\n",
            "\n",
            "Moderator:\n",
            "On behalf of JM Financial, that concludes this conference. Thank you for joining us and you may now ...\n",
            "\n",
            "Chunk Summaries:\n",
            "\n",
            "Summary 1:\n",
            "Transcripts of Analysts/Investor Meet/ Earnings Call of the Company are enclosed.\n",
            "\n",
            "Summary 2:\n",
            "Good day, ladies and gentlemen, and welcome to the SJS Enterprises 1Q FY24 earnings call.\n",
            "\n",
            "Summary 3:\n",
            "Good day and welcome to the 1Q FY2 4 earnings call of SJS Enterprises.\n",
            "\n",
            "Summary 4:\n",
            "Good day, everyone, and welcome to the Walter Pack India conference call.\n",
            "\n",
            "Summary 5:\n",
            "Q1 F Y24 pro forma numbers, which includes Walter Pack India, 36% revenue contribution\n",
            "\n",
            "Summary 6:\n",
            "Joe: Is there any change in your view of the company?\n",
            "\n",
            "Summary 7:\n",
            "SJS has been outperforming the industry for 15th consecutive quarter\n",
            "\n",
            "Summary 8:\n",
            "Q1 FY24 revenue grew by 13.6% on back of strong growth in automotive, export\n",
            "\n",
            "Summary 9:\n",
            "Company has deferred its chrome plating capacity expansion plan by a year to 24\n",
            "\n",
            "Summary 10:\n",
            "Mahendra Naredi, CEO, Exotech, answers questions on quarterly performance.\n",
            "\n",
            "Summary 11:\n",
            "Sanj ay Thapar, Devanshi Dhruva speak on margins, growth prospects.\n",
            "\n",
            "Summary 12:\n",
            "In an interview to CNBC-TV18, CEO of Exotech talks about the company's expansion plans.\n",
            "\n",
            "Summary 13:\n",
            "In an interview, Sanjay Thapar, CEO, SJS comments on delayed expansion.\n",
            "\n",
            "Summary 14:\n",
            "Amit Hiranandani: What would be the impact of capex cuts on standalone? Devanshi Dhruva: So for this year, we would be somewhere around 1 0-12 crores\n",
            "\n",
            "Summary 15:\n",
            "In an interview with CNBC-TV18, Mahendra Naredi, CEO, says margins will not be affected by capacity postponement.\n",
            "\n",
            "Summary 16:\n",
            "Devanshi Dhruva: We are only doing it more intelligently to make sure that our investments are as frugal as possible\n",
            "\n",
            "Summary 17:\n",
            "Devanshi Dhruva: No, nothing. Sanjay Thapar: We are on track.\n",
            "\n",
            "Summary 18:\n",
            "In a chat with CNBC-TV18, Mahendra Naredi, CEO, Walter Pack India shares his views.\n",
            "\n",
            "Summary 19:\n",
            "In an interview, Sanjay Thapar, CEO, SJS talks about acquisition of Walter Pack India.\n",
            "\n",
            "Summary 20:\n",
            "Q&A with Devanshi Dhruva, Ronak Mehta from JM Financial.\n",
            "\n",
            "Summary 21:\n",
            "Q.A. Joseph: What are the drivers for growth in your business?\n",
            "\n",
            "Summary 22:\n",
            "Sanjay Thapar: Walter Pack is forte of large in -mold forming parts\n",
            "\n",
            "Summary 23:\n",
            "In an interview, Devanshi Dhruva says there will be a lot of cross selling opportunities between Exotech and Walter Pack.\n",
            "\n",
            "Summary 24:\n",
            "In an interview, Sanjay Thapar, managing director, SJS Auto talks about winning orders from Autoliv and others.\n",
            "\n",
            "Summary 25:\n",
            "Devanshi Dhruva: Other expenses have increased on account of two reasons.\n",
            "\n",
            "Summary 26:\n",
            "In-Mold Electronics (IME) is still under development, says the company's CEO.\n",
            "\n",
            "Summary 27:\n",
            "In an interview, Sanjay Thapar, vice president, IME, BMW India talks about the company's plans\n",
            "\n",
            "Summary 28:\n",
            "Questions on Exotech sales quarter -on-quarter was slightly done.\n",
            "\n",
            "Summary 29:\n",
            "Mahendra Naredi: Exports have gone up to 11% from 9% last quarter.\n",
            "\n",
            "Summary 30:\n",
            "In an interview to CNBC-TV18, Devanshi Dhruva and Shrinja na Mittal share their views on the company.\n",
            "\n",
            "Summary 31:\n",
            "Moderator: Sanjay, can you give us guidance on exports?\n",
            "\n",
            "Summary 32:\n",
            "In a interview, Devanshi Dhruva, CEO, SJS Enterprises talks about the company's performance.\n",
            "\n",
            "Summary 33:\n",
            "In an interview, SJS chairman Sanjay Thapar talks about the acquisition of Walter Pack.\n",
            "\n",
            "Summary 34:\n",
            "Ridhima Goyal: Is there any plan to add WPI? Devanshi Dhruva: No, we don't have any plans to do that\n",
            "\n",
            "Summary 35:\n",
            "Sanjay Thapar: Not including WP I, almost 90% of the order book is confirmed for F Y24.\n",
            "\n",
            "Summary 36:\n",
            "In an interview with CNBC-TV18, Mahendra Naredi, CEO, Walter Pack talks about the company's performance.\n",
            "\n",
            "Summary 37:\n",
            "Sanjay Thapar: This guidance is on consolidated level of all these businesses\n",
            "\n",
            "Summary 38:\n",
            "Panel discussion on WPI-Walter Pack acquisition with Mahendra Naredi.\n",
            "\n",
            "Summary 39:\n",
            "In an interview, Sanjay Thapar, CEO, Walter Pack, talks about growth, IME.\n",
            "\n",
            "Summary 40:\n",
            "In an interview with CNBC-TV18, Devanshi Dhruva, CEO, Walter Pack India talks about growth prospects.\n",
            "\n",
            "Summary 41:\n",
            "SJS is trying to acquire some strategic customers.\n",
            "\n",
            "Summary 42:\n",
            "In an interview with CNBC-TV18, Sanjay Thapar and Amit Hiranandani share their views on the company\n",
            "\n",
            "Summary 43:\n",
            "Sanjay Thapar, Devanshi Dhruva and Vishal Khurana of SJS speak on investor call.\n",
            "\n",
            "Summary 44:\n",
            "In an interview, Sanjay Thapar, CEO, Essel Group, talks about EV, TV and other business segments\n",
            "\n",
            "Summary 45:\n",
            "Here is a verbatim transcript of the earnings call: Moderator: What is your view on the TV business?\n",
            "\n",
            "Analyzing with GPT...\n",
            "\n",
            "Investment Analysis Results:\n",
            "==================================================\n",
            "My Advice: {'result': 'Analysis Summary:\\nSJS Enterprises reported solid results during the first fiscal quarter of 2024, primarily driven by robust demand within the Automotive sector coupled with substantial contributions stemming from recent expansions such as the integration of Walter Park India into its operations. The firm continues to demonstrate resilience against broader economic challenges while maintaining profitability through prudent cost control measures alongside selective capital expenditure decisions. While no immediate red flags exist regarding future growth potential or competitive positioning, investors should monitor key triggers like margin sustainability amidst inflationary pressures and ongoing geopolitical tensions affecting supply chains before making long term commitments.\\n\\nFuture Growth Prospects Analysis:\\n1. Specific growth initiatives include expanding customer base via targeted bids towards securing contracts particularly within high value niches e.g., \"large in mold\" components production capabilities offered at subsidiaries like Walter Pack; furthermore, pursuing synergistic collaborations among group companies could lead to additional avenues of organic expansion along various verticals i.e., leveraging established relationships across multiple industries served may yield fruitful crossover ventures over time. Additionally, continued innovation efforts aimed specifically at developing next generation technologies such as \\'in mould electronics\\', although currently nascent but holds promise given rising consumer demands surrounding smart devices integrated seamlessly onto surfaces without compromising aesthetics nor functionality thus presenting significant opportunity downstream if successful implementation takes place sooner than later relative competitors who lag behind technologically speaking.\\n  \\n2. Regarding market expansion plans, focus remains largely centered upon domestic penetration however international exposure appears increasingly attractive considering upward trend observed recently vis-à-vis overseas clientele accounting now ~11%. Further exploration outside borders might prove beneficial provided adequate resources allocated judiciously balancing risk appetite versus reward expectations accordingly prioritize sustainable scalability goals rather than short sighted gains detrimental longer run objectives. It seems likely that diversification away from home turf represents viable strategy moving forward especially since globalization tends favorably promote economies scale efficiencies thereby bolster overall competiveness levels amongst rivals vying aggressively capture larger slice pie globally hence why staying vigilant here makes good sense strategically speaking going ahead.\\n\\n3. New products / services offerings showcase considerable interest toward cutting edge technological advancements notably evolving field embedded electronic systems incorporated directly vehicle interiors known collectively referred “In Mold Electronics”(IME). Although progress so far limited due early stage nature associated projects yet enthusiasm persists suggesting eventual payoff once technical hurdles resolved satisfactorily enough warrant commercial rollout eventually leading incremental revenues accretion bottom line figures subsequently translates higher valuations attributed underlying equity holders benefiting indirect fashion ultimately reflect positively return ratios calculated periodically measure success metrics commonly used gauge portfolio performances accurately determine optimal asset allocation mix tailored individualized needs preferences each unique circumstance presents different set variables requiring careful consideration when constructing suitable gameplans maximize returns minimize losses commensurable acceptable degrees uncertainty inherent volatile markets prone sudden swings direction unpredictable behavior patterns often defy rational explanation entirely dependent prevailing sentiment mood permeate atmosphere du jour subject matter expertise domain knowledge vital ingredient achieving desired outcomes consistently throughout lifecycle investing journey embarked upon jointly stakeholders alike must strive cooperatively work together achieve common goal mutual prosperity shared vision clearly articulated transparent manner leaving little room doubt ambiguity what lies ahead collective roadmap guiding principles chart course navigate treacherous waters navigating complex landscape successfully overcome inevitable obstacles encountered inevitably every step way reaching ultimate destination envisioned originally conceived initial concept stages iterative process refining ideas shaping reality gradually transform abstract concepts tangible realities manifest form visible light touch feel experience tactile sensation resonance deeply felt emotional core soul essence driving forces propelling momentum continuously pushing boundaries exploring unknown territories bold adventurers daring souls unafraid venture forth embrace challenge seek adventure thrive adversity cultivate strength endurance rise triumphantly victorious heroes destiny ordains fateful chapter written history books chronicled generations come remember forever etched eternal memory never forgotten lest they fade slowly disappear oblivion lost eternity silence echoes hollow emptiness filled void despair solitude darkness engulfs world devoid hope love joy peace serenity calmness wisdom understanding truth justice compassion kindness empathy forgiveness unity harmony balance equilibrium perfect symmetry flawless beauty divine perfection grace elegance poise sophistication eloquence charm wit humor intelligence creativity artistry genius brilliance intellect curiosity imagination dreams aspirations hopes wishes desires passions emotions feelings thoughts consciousness awareness perception intuition instinct gut feeling sixth sense inner voice silent whispers quiet murmurs faint rustling leaves wind blowing softly whisper secrets sacred ground holy land promised paradise heaven above earth below universe infinite cosmos everything exists everywhere always', 'status': True, 'server_code': 1}\n"
          ]
        }
      ]
    }
  ]
}